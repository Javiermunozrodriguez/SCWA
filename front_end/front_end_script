# En este capitulo del trabajo , se desarrolla la programación necesaria para la visualización de los datos
# enriqueciendo el resultado de las predicciones con varaibles georeferenciados

library(readr)

#por favor, el siguiente dataset, hay que cargarlos desde la carpeta que esté alojado en su servidor

consumption_prediction_2016 <- read_csv("C:/Users/jmuro/Desktop/tfm/step_04_forecastmodels/consumption_prediction_2016.csv")

View(consumption_prediction_2016)

#cargamos las librerias que necesitamos para comenzar a plantear un modelo resultado

if(!require("plyr")){
  install.packages("plyr")
  library("plyr")
}
install.packages("caTools")
if(!require("caTools")){
  install.packages("caTools")
  library("caTools")
}

if(!require("ROCR")){
  install.packages("ROCR")
  library("ROCR")
}

library(ggplot2) 

library(tidyverse)

# primero vams a enriquecer la data set de resultados con las coordenadas de algunos puntos de distrifución de lso distritos considerados, 
# escalando y distribuyendo en torno a un criterio de asignación según el distrito. Son datos generados de manera aleatoria, sin
# conprometer al natiraleza privada de los datos, se simula para unas coordenadas normalmente distribuidas

Real_consumption_data_madrid_2016 <- read_excel("C:/Users/jmuro/Desktop/tfm/step_05_front end/Real_consumption_data_madrid_2016.xls")

View(Real_consumption_data_madrid_2016)

# limpiamos un poco los Datos para tener un perspectiva de lo que se intenta implementar

Real_consumption_data_madrid_2016 <- Real_consumption_data_madrid_2016[,-c(1)] # quitamos al primera comulna por defecto de carga

Real_consumption_data_madrid_2016 <- Real_consumption_data_madrid_2016[-c(1,2,3,4,5,6,29,30),] # las filas que no aportan inforamción


# Quitamos las filas de varibles colineales, litros por habitante e índices que no aportan información

Real_consumption_data_madrid_2016 <- Real_consumption_data_madrid_2016[,-c(4,5)] 

colnames(Real_consumption_data_madrid_2016)<-c("Distrito", " Consumo [m3]", "Poblacion", "Poblacion_relativa_%", "Consumo_relativo_%")

# vamos a cambiar la clase para poder opeararla

Real_consumption_data_madrid_2016[, c(2:5)] <- sapply(Real_consumption_data_madrid_2016[, c(2:5)],as.character)

Real_consumption_data_madrid_2016[, c(2:5)] <- sapply(Real_consumption_data_madrid_2016[, c(2:5)],as.numeric)


Real_consumption_data_madrid_2016[, c(1)] <- sapply(Real_consumption_data_madrid_2016[, c(1)],as.character)


# Vemos que porcentajes tenemos por distrito

Real_consumption_data_madrid_2016$`Consumo_relativo_%` <- Real_consumption_data_madrid_2016$`Consumo_relativo_%`*100

Real_consumption_data_madrid_2016$`Población_relativa_%` <- Real_consumption_data_madrid_2016$`Población_relativa_%`*100

# también eliminamos la fila de consumos sin registro de consumidores, porque, no vamos a poder absorber este patrón en el encaje
# con las predicciones

Real_consumption_data_madrid_2016 <- Real_consumption_data_madrid_2016[-c(22),]

# veamos la coherencia de las columnas de pesos relativos

sum(Real_consumption_data_madrid_2016$`Población_relativa_%`)

sum(Real_consumption_data_madrid_2016$`Consumo_relativo_%`)

write.csv(Real_consumption_data_madrid_2016,file="Real_consumption_data_madrid_2016.csv")


# hay un pequeño sesgo en los consumos por quitarnos al parte de consumos sin registrar, pero avancemos con lso que si sabemos 
# de al fotografía del 2016


# la idea siguiente en crear un dataset que recoja los pesos de las poblaciones por distritos y un regsitro aleatorio de direccione UTM
# incluidas en las 178598 observaciones potenciales que podemos asiganar

# en criterio de asignación va aser por  peso relativo de los consumos, que es un huella más consistente con la filosofia de construcción de la
# madriz de predicciones 

ggplot(Real_consumption_data_madrid_2016, aes(x = `Consumo_relativo_%`, y = `Población_relativa_%`)) + geom_point() +geom_smooth(model="lm")

# se ve una tendencia clara entre el consumos relativos 

ggplot(Real_consumption_data_madrid_2016, aes(x = Distrito, y = ` Consumo [m3]`))+geom_bar(stat = "identity")+ theme(axis.text.x = element_text(angle = 90, hjust = 1))

ggplot(Real_consumption_data_madrid_2016, aes(x = Distrito, y = Población))+geom_bar(stat = "identity")+ theme(axis.text.x = element_text(angle = 90, hjust = 1))



colnames(consumption_prediction_2016)<-c("Tipo_consumidor", "2016/01","2016/02","2016/03","2016/04","2016/05","2016/06","2016/07", "2016/08","2016/09","2016/10","2016/11","2016/12")

write.csv(consumption_prediction_2016,file="consumption_prediction_2016.csv")


sum(consumption_prediction_2016[c(1:2),c("2016/01","2016/02","2016/03","2016/04","2016/05","2016/06","2016/07", "2016/08","2016/09","2016/10","2016/11","2016/12")])




head(consumption_prediction_2016)

# añadimos una columna de distrito para asignarle un valor entre


Distrito <- consumption_prediction_2016$Tipo_consumidor


class(consumption_prediction_2016$Distrito [2])


consumption_prediction_2016[, c(1)] <- sapply(consumption_prediction_2016[, c(1)],as.character)


consumption_prediction_2016$Distrito[1:7113]= "Centro"

consumption_prediction_2016 <- cbind(Distrito,consumption_prediction_2016)

--------------------------------
# esta parte del código se puede mejorar, haciendo más elegante el loop que recorrael datafraem y asignar el distrito. trabajjaremso en en una segunda fase
# en este punto

total=0

for (i in 1:178598) {
  
  total<-total+sum(consumption_prediction_2016[i,c(3:14)])
    
    if (total == 7296331){
      
      consumption_prediction_2016$Distrito[i] == "XXX"
      
    }

}

library(dplyr)

Total_2016<-colSums (select (consumption_prediction_2016, contains ("2016")))

sum(Total_2016)

-----------------------------------------------

  
#Asignación de distritos a los datos


#vemos cuales son los consumos aplicados al matriz de prediccion consumption_prediction_2016 por cada distrito, empezamos por el centro


centro_pred_consumption= sum(Total_2016,1:12)*(Real_consumption_data_madrid_2016$`Consumo_relativo_%`[1]/100)

sum(consumption_prediction_2016[c(1:6612),c(3:14)])

consumption_prediction_2016$Distrito[1:6612]= "Centro"

centro_pred_consumption

# Arganzuela

arganzuela_pred_consumption= sum(Total_2016,1:12)*(Real_consumption_data_madrid_2016$`Consumo_relativo_%`[2]/100)

sum(consumption_prediction_2016[c(6613:8169),c(3:14)])

consumption_prediction_2016$Distrito[6613:8169]= "Arganzuela"


#Retiro

retiro_pred_consumption= sum(Total_2016,1:12)*(Real_consumption_data_madrid_2016$`Consumo_relativo_%`[3]/100)

sum(consumption_prediction_2016[c(8170:8966),c(3:14)])

consumption_prediction_2016$Distrito[8170:8966]= "Retiro"

#Salamanca

salamanca_pred_consumption= sum(Total_2016,1:12)*(Real_consumption_data_madrid_2016$`Consumo_relativo_%`[4]/100)

sum(consumption_prediction_2016[c(8967:10630),c(3:14)])

consumption_prediction_2016$Distrito[8967:10630]= "Salamanca"

#Chamartin

chamartin_pred_consumption= sum(Total_2016,1:12)*(Real_consumption_data_madrid_2016$`Consumo_relativo_%`[5]/100)

sum(consumption_prediction_2016[c(10631:14156),c(3:14)])

consumption_prediction_2016$Distrito[10631:14156]= "Chamartin"

#Tetuan

tetuan_pred_consumption= sum(Total_2016,1:12)*(Real_consumption_data_madrid_2016$`Consumo_relativo_%`[6]/100)

sum(consumption_prediction_2016[c(14157:30969),c(3:14)])

consumption_prediction_2016$Distrito[14157:30969]= "Tetuan"

#Chamberi

chamberi_pred_consumption= sum(Total_2016,1:12)*(Real_consumption_data_madrid_2016$`Consumo_relativo_%`[7]/100)

sum(consumption_prediction_2016[c(30970:59301),c(3:14)])

consumption_prediction_2016$Distrito[30970:59301]= "Chamberi"

#Fuencarral

fuencarral_pred_consumption= sum(Total_2016,1:12)*(Real_consumption_data_madrid_2016$`Consumo_relativo_%`[8]/100)

sum(consumption_prediction_2016[c(59302:77081),c(3:14)])

consumption_prediction_2016$Distrito[59302:77081]= "Fuencarral"

#Moncloa

moncloa_pred_consumption= sum(Total_2016,1:12)*(Real_consumption_data_madrid_2016$`Consumo_relativo_%`[9]/100)

sum(consumption_prediction_2016[c(77082:79273),c(3:14)])

consumption_prediction_2016$Distrito[77082:79273]= "Moncloa"


#Latina

latina_pred_consumption= sum(Total_2016,1:12)*(Real_consumption_data_madrid_2016$`Consumo_relativo_%`[10]/100)

sum(consumption_prediction_2016[c(79274:81492),c(3:14)])

consumption_prediction_2016$Distrito[79274:81492]= "Latina"

#Carabanchel

carabanchel_pred_consumption= sum(Total_2016,1:12)*(Real_consumption_data_madrid_2016$`Consumo_relativo_%`[11]/100)

sum(consumption_prediction_2016[c(81492:83947),c(3:14)])

consumption_prediction_2016$Distrito[81493:83947]= "Carabanchel"


#Usera

usera_pred_consumption= sum(Total_2016,1:12)*(Real_consumption_data_madrid_2016$`Consumo_relativo_%`[12]/100)

sum(consumption_prediction_2016[c(83948:86521),c(3:14)])

consumption_prediction_2016$Distrito[83948:86521]= "Usera"

# Puentevallecas

puentevallecas_pred_consumption= sum(Total_2016,1:12)*(Real_consumption_data_madrid_2016$`Consumo_relativo_%`[13]/100)

sum(consumption_prediction_2016[c(86522:94421),c(3:14)])

consumption_prediction_2016$Distrito[86522:94421]= "Puente_Vallecas"

# Moratalaz

moratalaz_pred_consumption= sum(Total_2016,1:12)*(Real_consumption_data_madrid_2016$`Consumo_relativo_%`[14]/100)

sum(consumption_prediction_2016[c(94422:95571),c(3:14)])

consumption_prediction_2016$Distrito[94422:95571]= "Moratalaz"


# Ciudad Lineal

ciudadlineal_pred_consumption= sum(Total_2016,1:12)*(Real_consumption_data_madrid_2016$`Consumo_relativo_%`[15]/100)

sum(consumption_prediction_2016[c(95572:113461),c(3:14)])

consumption_prediction_2016$Distrito[95572:113461]= "Ciudad_Lineal"


# Hortaleza

hortaleza_pred_consumption= sum(Total_2016,1:12)*(Real_consumption_data_madrid_2016$`Consumo_relativo_%`[16]/100)

sum(consumption_prediction_2016[c(113462:139587),c(3:14)])

consumption_prediction_2016$Distrito[113462:139587]= "Hortaleza"


# Villaverde

villaverde_pred_consumption= sum(Total_2016,1:12)*(Real_consumption_data_madrid_2016$`Consumo_relativo_%`[17]/100)

sum(consumption_prediction_2016[c(139588:161755),c(3:14)])

consumption_prediction_2016$Distrito[139588:161755]= "Villaverde"


# Vallecas

vallecas_pred_consumption= sum(Total_2016,1:12)*(Real_consumption_data_madrid_2016$`Consumo_relativo_%`[18]/100)

sum(consumption_prediction_2016[c(161756:168490),c(3:14)])

consumption_prediction_2016$Distrito[161756:168490]= "Vallecas"


# Vicalvaro

vicalvaro_pred_consumption= sum(Total_2016,1:12)*(Real_consumption_data_madrid_2016$`Consumo_relativo_%`[19]/100)

sum(consumption_prediction_2016[c(168491:169489),c(3:14)])

consumption_prediction_2016$Distrito[168491:169489]= "Vicalvaro"

# san blas

sanblas_pred_consumption= sum(Total_2016,1:12)*(Real_consumption_data_madrid_2016$`Consumo_relativo_%`[20]/100)

sum(consumption_prediction_2016[c(169490:172190),c(3:14)])

consumption_prediction_2016$Distrito[169490:172189]= "San_Blas"

# Barajas

barajas_pred_consumption= sum(Total_2016,1:12)*(Real_consumption_data_madrid_2016$`Consumo_relativo_%`[21]/100)

sum(consumption_prediction_2016[c(172190:178598),c(3:14)])

consumption_prediction_2016$Distrito[172190:178598]= "Barajas"

#ponemos en minusculas la columna de consumidores

consumption_prediction_2016$Tipo_consumidor<- tolower(consumption_prediction_2016$Tipo_consumidor)

write.csv(consumption_prediction_2016,file="consumption_prediction_2016_final.csv")

# vamso a enriquecer la tabla cons las coordenadas desde lso archivos de catastro de madrid

"https://www1.sedecatastro.gob.es/Cartografia/mapa.aspx?del=28&mun=92&refcat=28092A024000560000OK&final="

require(XML)

install.packages("XML")
library("XML")


centro_coor <- "C:/Users/jmuro/Desktop/tfm/step_05_front end/cartografia Madrid/ConsultaMasiva_centro.xml"

doc_coor_centro <- xmlTreeParse(centro_coor,getDTD=T,addAttributeNamespaces=T)

arriba_centro = xmlRoot(doc_coor_centro)

#Vemos los nombres de los campos de la tabla, convirtiendo a un Data frame

names(arriba_centro[[1]])

datos_centro=xmlToDataFrame(centro_coor)

head(datos_centro)


# como se puede ver en el resultado, las varibles que descargamso del catastro directamente no aportan las coordenadas de la las parcelas
# para mantener el resultado dentro de los terminos privados que rige este tipo de inforamción
# vamso a generar una seire de coordenadas aleatorias a aprtir del polígono de coordenadas UTM huso 30 de cada uno de los distritos
# aporta la web del catastro de Madrid, ya en trasforamdas en coordendas sexa decimales

install.packages("sp")

library("sp")

# para la zona centro

east_centro <- c(441418.95, 440996.00, 440158.96, 439260.08, 439681.65, 439288.63, 438869.13, 438627.51, 439166.34, 439059.00, 439186.96,
                439587.87, 440379.53, 441171.17, 441295.74, 441161.86, 441217.26, 441418.95)

north_centro <- c(4475157.64, 4475448.17, 4475666.59, 4475795.67, 4474982.84, 4474646.55, 4474638.35, 4473943.95, 4473933.75, 4473629.94, 
                 4473360.20, 4473146.50, 4472937.64, 4473229.22, 4473355.31, 4474075.06, 4474531.22, 4475157.64)

frame_coor_centro <- data.frame(east_centro,north_centro)



# utilizamos las funciones del paquete sp de R para trasforam coordenadas UTM de huso 30 a coordenadas hexadecimales

utmcoor_centro<-SpatialPoints(cbind(frame_coor_centro$east_centro,frame_coor_centro$north_centro), proj4string=CRS("+proj=utm +zone=30"))

longlatcoor_centro<-spTransform(utmcoor_centro,CRS("+proj=longlat"))

# volcamos laal transformación en el frame de coordenadas del centro

frame_coor_centro$x <- coordinates(longlatcoor_centro)[,1]
frame_coor_centro$y <- coordinates(longlatcoor_centro)[,2]

frame_coor_centro <- frame_coor_centro[,-c(1,2)]



# El siguiente paso será generar un nube de coordenadas decimales para las posiciones de lso consumidores de la zona centro,
# dentro de los límites de poligono de coordendas de esta zona

n <- sum(consumption_prediction_2016$Distrito == "Centro")

df <- frame_coor_centro

coords <- as.matrix(df)


P1 = Polygon(coords)
Ps1 = SpatialPolygons(list(Polygons(list(P1), ID = "a")), proj4string=CRS("+proj=utm +zone=30"))
plot(Ps1, axes = TRUE)


coor_frame_random <- as.data.frame(spsample(Ps1,n,"random"))


# creamos dos columnas de lat y longitud en el data frame de predicciones pàra asignar los valores calculados

consumption_prediction_2016$lat <- c(1:178598)

consumption_prediction_2016$lon <- c(1:178598)

consumption_prediction_2016$lat[1:6612] <- coor_frame_random$y

consumption_prediction_2016$lon[1:6612] <- coor_frame_random$x


# bien, ahora hay que repetir el mismos código para cada distrito, que en una fase posterior reprogramaremos para que sea un función

# más limpia para simplificar más la solución

--------------------------------------------------------------------------
# Arganzuela

"https://www1.sedecatastro.gob.es/Cartografia/mapa.aspx?del=28&mun=92&refcat=28092A024000560000OK&final="

east_arganda <- c(439166.39, 438627.58, 438783.88, 438716.04, 438756.43, 438828.22, 438961.65, 439261.78,
                  439430.29, 439582.03, 440002.37, 440322.14, 440648.90, 440516.54, 441322.20, 441630.40,
                  441905.10, 441770.56, 442118.92, 442306.71, 442828.89, 442692.58, 441918.68, 441998.82,
                  441598.01, 441285.29, 441188.28, 440396.42, 439541.63, 439150.24, 439053.13, 439166.39)

north_arganda <- c(4473939.56, 4473952.65, 4473472.58, 4473014.62, 4472607.98, 4472479.70, 4472406.06, 4472409.42,
                   4472350.02, 4472377.81, 4472110.33, 4472017.80, 4471701.74, 4471546.05, 4470607.91, 4470515.51,
                   4470612.08, 4471301.10, 4471507.39, 4471296.95, 4471754.47, 4472219.90, 4472742.45, 4472933.37,
                   4473093.19, 4473339.40, 4473226.98, 4472931.42, 4473150.12, 4473385.44, 4473624.18,4473939.56)



frame_coor_arganda<- data.frame(east_arganda,north_arganda)

utmcoor_arganda<-SpatialPoints(cbind(frame_coor_arganda$east_arganda,frame_coor_arganda$north_arganda), proj4string=CRS("+proj=utm +zone=30"))

longlatcoor_arganda<-spTransform(utmcoor_arganda,CRS("+proj=longlat"))

frame_coor_arganda$x <- coordinates(longlatcoor_arganda)[,1]
frame_coor_arganda$y <- coordinates(longlatcoor_arganda)[,2]

# el número de coordendas será igual al número de consumidores de Arganzuela

frame_coor_arganda <- frame_coor_arganda[,-c(1,2)]

n <- sum(consumption_prediction_2016$Distrito == "Arganzuela")

df <- frame_coor_arganda

coords <- as.matrix(df)


P1 = Polygon(coords)
Ps1 = SpatialPolygons(list(Polygons(list(P1), ID = "a")), proj4string=CRS("+proj=utm +zone=30"))
plot(Ps1, axes = TRUE)


coor_frame_random <- as.data.frame(spsample(Ps1,n,"random"))


# creamos dos columnas de lat y longitud en el data frame de predicciones para asignar los valores calculados


consumption_prediction_2016$lat[6613:8169] <- coor_frame_random$y

consumption_prediction_2016$lon[6613:8169] <- coor_frame_random$x
-------------------------------------------------------------
# Retiro
  
"https://www1.sedecatastro.gob.es/Cartografia/mapa.aspx?del=28&mun=92&refcat=28092A024000560000OK&final="

east_retiro <- c(441297.04, 441154.69, 441233.54, 442318.90, 443256.34, 444098.94, 444106.60, 443532.25,
                 443272.97, 442855.21, 442732.75, 442542.04, 441924.46, 442013.41, 441589.32, 441297.04)

north_retiro <- c(4473350.92, 4474144.21, 4474541.11, 4474776.39, 4474717.01, 4474437.95, 4474292.82, 4473063.87,
                  4472293.85, 4471765.88, 4472138.33, 4472345.85, 4472736.60, 4472936.16, 4473099.06, 4473350.92)

frame_coor_retiro<- data.frame(east_retiro,north_retiro)

utmcoor_retiro<-SpatialPoints(cbind(frame_coor_retiro$east_retiro,frame_coor_retiro$north_retiro), proj4string=CRS("+proj=utm +zone=30"))

longlatcoor_retiro<-spTransform(utmcoor_retiro,CRS("+proj=longlat"))

frame_coor_retiro$x <- coordinates(longlatcoor_retiro)[,1]
frame_coor_retiro$y <- coordinates(longlatcoor_retiro)[,2]

# el número de coordendas será igual al número de consumidores de Arganzuela

frame_coor_retiro <- frame_coor_retiro[,-c(1,2)]

n <- sum(consumption_prediction_2016$Distrito == "Retiro")

df <- frame_coor_retiro

coords <- as.matrix(df)


P1 = Polygon(coords)
Ps1 = SpatialPolygons(list(Polygons(list(P1), ID = "a")), proj4string=CRS("+proj=utm +zone=30"))
plot(Ps1, axes = TRUE)


coor_frame_random <- as.data.frame(spsample(Ps1,n,"random"))


# creamos dos columnas de lat y longitud en el data frame de predicciones para asignar los valores calculados


consumption_prediction_2016$lat[8170:8966] <- coor_frame_random$y

consumption_prediction_2016$lon[8170:8966] <- coor_frame_random$x

-----------------------------------------------
  
# Salamanca
  
"https://www1.sedecatastro.gob.es/Cartografia/mapa.aspx?del=28&mun=92&refcat=28092A024000560000OK&final="

east_salamanca <- c(441237.56, 442310.41, 443265.72, 444099.60, 443962.11, 444075.65, 444077.46, 443997.53,
                    442517.31, 441443.26, 441636.41, 441237.56)

north_salamanca <- c(4474533.10, 4474770.96, 4474726.74, 4474416.84, 4475862.09, 4476726.83, 4476968.83,
                     4477293.48, 4476504.80, 4476607.47, 4476027.54, 4474533.10)


frame_coor_salamanca<- data.frame(east_salamanca,north_salamanca)

utmcoor_salamanca<-SpatialPoints(cbind(frame_coor_salamanca$east_salamanca,frame_coor_salamanca$north_salamanca), proj4string=CRS("+proj=utm +zone=30"))

longlatcoor_salamanca<-spTransform(utmcoor_salamanca,CRS("+proj=longlat"))

frame_coor_salamanca$x <- coordinates(longlatcoor_salamanca)[,1]
frame_coor_salamanca$y <- coordinates(longlatcoor_salamanca)[,2]

# el número de coordendas será igual al número de consumidores de Arganzuela

frame_coor_salamanca <- frame_coor_salamanca[,-c(1,2)]

n <- sum(consumption_prediction_2016$Distrito == "Salamanca")

df <- frame_coor_salamanca

coords <- as.matrix(df)


P1 = Polygon(coords)
Ps1 = SpatialPolygons(list(Polygons(list(P1), ID = "a")), proj4string=CRS("+proj=utm +zone=30"))
plot(Ps1, axes = TRUE)


coor_frame_random <- as.data.frame(spsample(Ps1,n,"random"))

# creamos dos columnas de lat y longitud en el data frame de predicciones para asignar los valores calculados


consumption_prediction_2016$lat[8967:10630] <- coor_frame_random$y

consumption_prediction_2016$lon[8967:10630] <- coor_frame_random$x

--------------------------------------
  
  
  # Chamartin
  
  "https://www1.sedecatastro.gob.es/Cartografia/mapa.aspx?del=28&mun=92&refcat=28092A024000560000OK&final="

east_chamartin <- c(442525.70, 443977.09, 443365.39, 442793.25, 442852.20, 442721.39,441930.07,
                    441570.34, 441359.67, 441451.36, 442525.70)

north_chamartin <- c(4476525.25, 4477314.14, 4479734.28, 4480816.97, 4481529.86, 4481645.65,
                     4481495.97, 4479698.88, 4476977.31, 4476591.00, 4476525.25)

frame_coor_chamartin<- data.frame(east_chamartin,north_chamartin)

utmcoor_chamartin<-SpatialPoints(cbind(frame_coor_chamartin$east_chamartin,frame_coor_chamartin$north_chamartin), proj4string=CRS("+proj=utm +zone=30"))

longlatcoor_chamartin<-spTransform(utmcoor_chamartin,CRS("+proj=longlat"))

frame_coor_chamartin$x <- coordinates(longlatcoor_chamartin)[,1]
frame_coor_chamartin$y <- coordinates(longlatcoor_chamartin)[,2]

# el número de coordendas será igual al número de consumidores de Arganzuela

frame_coor_chamartin <- frame_coor_chamartin[,-c(1,2)]

n <- sum(consumption_prediction_2016$Distrito == "Chamartin")

df <- frame_coor_chamartin

coords <- as.matrix(df)


P1 = Polygon(coords)
Ps1 = SpatialPolygons(list(Polygons(list(P1), ID = "a")), proj4string=CRS("+proj=utm +zone=30"))
plot(Ps1, axes = TRUE)


coor_frame_random <- as.data.frame(spsample(Ps1,n,"random"))

# creamos dos columnas de lat y longitud en el data frame de predicciones para asignar los valores calculados


consumption_prediction_2016$lat[10631:14156] <- coor_frame_random$y

consumption_prediction_2016$lon[10631:14156] <- coor_frame_random$x
----------------------------------------------------
  
# Tetuan
  
"https://www1.sedecatastro.gob.es/Cartografia/mapa.aspx?del=28&mun=92&refcat=28092A024000560000OK&final="

east_tetuan <- c(441371.92, 441558.53, 441687.13, 441136.61, 439876.86, 440062.12,
                 439551.69, 439898.96, 441371.92) 

                 
north_tetuan <- c(4477489.94, 4479768.68, 4480423.72, 4480555.13, 4480011.62, 4479501.68, 
                  4478484.66, 4477636.97, 4477489.94)

frame_coor_tetuan<- data.frame(east_tetuan,north_tetuan)

utmcoor_tetuan<-SpatialPoints(cbind(frame_coor_tetuan$east_tetuan,frame_coor_tetuan$north_tetuan), proj4string=CRS("+proj=utm +zone=30"))

longlatcoor_tetuan<-spTransform(utmcoor_tetuan,CRS("+proj=longlat"))

frame_coor_tetuan$x <- coordinates(longlatcoor_tetuan)[,1]
frame_coor_tetuan$y <- coordinates(longlatcoor_tetuan)[,2]

# el número de coordendas será igual al número de consumidores de Arganzuela

frame_coor_tetuan <- frame_coor_tetuan[,-c(1,2)]

n <- sum(consumption_prediction_2016$Distrito == "Tetuan")

df <- frame_coor_tetuan

coords <- as.matrix(df)


P1 = Polygon(coords)
Ps1 = SpatialPolygons(list(Polygons(list(P1), ID = "a")), proj4string=CRS("+proj=utm +zone=30"))
plot(Ps1, axes = TRUE)


coor_frame_random <- as.data.frame(spsample(Ps1,n,"random"))

# creamos dos columnas de lat y longitud en el data frame de predicciones para asignar los valores calculados


consumption_prediction_2016$lat[14157:30969] <- coor_frame_random$y

consumption_prediction_2016$lon[14157:30969] <- coor_frame_random$x
------------------------------
  
# Chamberi
  
"https://www1.sedecatastro.gob.es/Cartografia/mapa.aspx?del=28&mun=92&refcat=28092A024000560000OK&final="

east_chamberi <- c(441379.99, 439886.51, 439362.34, 439144.81, 438979.05, 438957.12, 439155.22,
                   439095.82, 439254.07, 440981.40, 441440.14, 441632.52, 441346.90, 441379.99)


north_chamberi <- c(4477469.37, 4477624.77, 4477473.13, 4477561.03, 4477431.12, 4477267.23, 4476814.40,
                    4476092.89, 4475800.32, 4475482.92, 4475155.19, 4476056.29, 4476924.09, 4477469.37)

frame_coor_chamberi<- data.frame(east_chamberi,north_chamberi)

utmcoor_chamberi<-SpatialPoints(cbind(frame_coor_chamberi$east_chamberi,frame_coor_chamberi$north_chamberi), proj4string=CRS("+proj=utm +zone=30"))

longlatcoor_chamberi<-spTransform(utmcoor_chamberi,CRS("+proj=longlat"))

frame_coor_chamberi$x <- coordinates(longlatcoor_chamberi)[,1]
frame_coor_chamberi$y <- coordinates(longlatcoor_chamberi)[,2]

# el número de coordendas será igual al número de consumidores de Arganzuela

frame_coor_chamberi<- frame_coor_chamberi[,-c(1,2)]

n <- sum(consumption_prediction_2016$Distrito == "Chamberi")

df <- frame_coor_chamberi

coords <- as.matrix(df)


P1 = Polygon(coords)
Ps1 = SpatialPolygons(list(Polygons(list(P1), ID = "a")), proj4string=CRS("+proj=utm +zone=30"))
plot(Ps1, axes = TRUE)


coor_frame_random <- as.data.frame(spsample(Ps1,n,"random"))


# creamos dos columnas de lat y longitud en el data frame de predicciones para asignar los valores calculados


consumption_prediction_2016$lat[30970:59301] <- coor_frame_random$y

consumption_prediction_2016$lon[30970:59301] <- coor_frame_random$x
--------------------------------------------------------------------

# Fuencarral
  
"https://www1.sedecatastro.gob.es/Cartografia/mapa.aspx?del=28&mun=92&refcat=28092A024000560000OK&final="

east_fuencarral <- c(441742.43, 441922.00, 442878.58, 443041.54, 444174.04, 444108.80, 443506.89, 442196.85, 439547.26, 
                     437663.82, 437311.78, 436313.36, 436308.40, 437363.11, 439594.67, 440324.14, 440644.09, 441742.43)


north_fuencarral <- c(4480652.89, 4481516.53, 4481751.03, 4482614.70, 4483839.82, 4484467.30, 4484840.63, 4485657.84, 4484047.93,
                      4482173.91, 4481414.36, 4481127.62, 4480545.47, 4480663.67, 4480239.41, 4480352.46, 4480731.22, 4480652.89)

frame_coor_fuencarral<- data.frame(east_fuencarral,north_fuencarral)

utmcoor_fuencarral<-SpatialPoints(cbind(frame_coor_fuencarral$east_fuencarral,frame_coor_fuencarral$north_fuencarral), proj4string=CRS("+proj=utm +zone=30"))

longlatcoor_fuencarral<-spTransform(utmcoor_fuencarral,CRS("+proj=longlat"))

frame_coor_fuencarral$x <- coordinates(longlatcoor_fuencarral)[,1]
frame_coor_fuencarral$y <- coordinates(longlatcoor_fuencarral)[,2]

# el número de coordendas será igual al número de consumidores de Arganzuela

frame_coor_fuencarral<- frame_coor_fuencarral[,-c(1,2)]

n <- sum(consumption_prediction_2016$Distrito == "Fuencarral")

df <- frame_coor_fuencarral

coords <- as.matrix(df)


P1 = Polygon(coords)
Ps1 = SpatialPolygons(list(Polygons(list(P1), ID = "a")), proj4string=CRS("+proj=utm +zone=30"))
plot(Ps1, axes = TRUE)


coor_frame_random <- as.data.frame(spsample(Ps1,n,"random"))


# creamos dos columnas de lat y longitud en el data frame de predicciones para asignar los valores calculados


consumption_prediction_2016$lat[59302:77081] <- coor_frame_random$y

consumption_prediction_2016$lon[59302:77081] <- coor_frame_random$x

-------------------------------------------
  
# Moncloa
  
"https://www1.sedecatastro.gob.es/Cartografia/mapa.aspx?del=28&mun=92&refcat=28092A024000560000OK&final="

east_moncloa <- c(439506.78, 438254.43, 433877.42, 432192.56, 429149.16, 429064.59, 431270.58, 432567.87,
                  433201.36, 434547.62, 437278.22, 437448.77, 437714.60, 438754.06, 439282.13, 439655.35,
                  439055.10, 439029.63, 439919.51, 439539.47, 439937.19, 439506.78)


north_moncloa <- c(4480059.71, 4480438.96, 4480730.56, 4480122.41, 4481282.24, 4480610.64, 4479683.86, 4478831.38, 4477386.09,
                   4477353.69, 4477408.26, 4476135.17, 4475414.99, 4474589.91, 4474688.20, 4474997.02, 4476150.65, 4477574.27,
                   4477632.71, 4478501.16, 4479322.25, 4480059.71)

frame_coor_moncloa<- data.frame(east_moncloa,north_moncloa)

utmcoor_moncloa<-SpatialPoints(cbind(frame_coor_moncloa$east_moncloa,frame_coor_moncloa$north_moncloa), proj4string=CRS("+proj=utm +zone=30"))

longlatcoor_moncloa<-spTransform(utmcoor_moncloa,CRS("+proj=longlat"))

frame_coor_moncloa$x <- coordinates(longlatcoor_moncloa)[,1]
frame_coor_moncloa$y <- coordinates(longlatcoor_moncloa)[,2]

# el número de coordendas será igual al número de consumidores de Arganzuela

frame_coor_moncloa<- frame_coor_moncloa[,-c(1,2)]

n <- sum(consumption_prediction_2016$Distrito == "Moncloa")

df <- frame_coor_moncloa

coords <- as.matrix(df)


P1 = Polygon(coords)
Ps1 = SpatialPolygons(list(Polygons(list(P1), ID = "a")), proj4string=CRS("+proj=utm +zone=30"))
plot(Ps1, axes = TRUE)


coor_frame_random <- as.data.frame(spsample(Ps1,n,"random"))

# creamos dos columnas de lat y longitud en el data frame de predicciones para asignar los valores calculados


consumption_prediction_2016$lat[77082:79273] <- coor_frame_random$y

consumption_prediction_2016$lon[77082:79273] <- coor_frame_random$x

----------------------------------
  
  
# latina
  
"https://www1.sedecatastro.gob.es/Cartografia/mapa.aspx?del=28&mun=92&refcat=28092A024000560000OK&final="

east_latina <- c(438681.55, 437092.54, 436271.88, 435521.59, 435097.37, 434075.67, 433616.23, 432286.40,
                 431491.83, 433092.29, 433854.49, 434445.13, 435243.73, 435324.69, 435576.97, 436125.20,
                 436772.09, 436935.88, 438639.87, 438681.55)


north_latina <- c(4474286.85, 4473438.24, 4473346.67, 4472815.44, 4472359.40, 4472384.73, 4471686.86, 4469999.10,
                  4468749.80, 4467922.22, 4468326.16, 4467976.01, 4468786.32, 4469569.92, 4470627.05, 4470634.68,
                  4471101.32, 4471465.29, 4473220.22, 4474286.85)

frame_coor_latina<- data.frame(east_latina,north_latina)

utmcoor_latina<-SpatialPoints(cbind(frame_coor_latina$east_latina, frame_coor_latina$north_latina), proj4string=CRS("+proj=utm +zone=30"))

longlatcoor_latina<-spTransform(utmcoor_latina,CRS("+proj=longlat"))

frame_coor_latina$x <- coordinates(longlatcoor_latina)[,1]
frame_coor_latina$y <- coordinates(longlatcoor_latina)[,2]

# el número de coordendas será igual al número de consumidores de Arganzuela

frame_coor_latina<- frame_coor_latina[,-c(1,2)]

n <- sum(consumption_prediction_2016$Distrito == "Latina")

df <- frame_coor_latina

coords <- as.matrix(df)


P1 = Polygon(coords)
Ps1 = SpatialPolygons(list(Polygons(list(P1), ID = "a")), proj4string=CRS("+proj=utm +zone=30"))
plot(Ps1, axes = TRUE)


coor_frame_random <- as.data.frame(spsample(Ps1,n,"random"))

# creamos dos columnas de lat y longitud en el data frame de predicciones para asignar los valores calculados


consumption_prediction_2016$lat[79274:81492] <- coor_frame_random$y

consumption_prediction_2016$lon[79274:81492] <- coor_frame_random$x

-------------------------------
  
# Carabanchel
  
"https://www1.sedecatastro.gob.es/Cartografia/mapa.aspx?del=28&mun=92&refcat=28092A024000560000OK&final="

east_carabanchel <- c(438789.82, 438584.66, 436973.31, 436792.73, 436187.19, 435626.39, 435320.21, 435309.44,
                      434544.46, 435479.04, 437676.24, 438775.37, 439056.60, 439477.14, 439886.78, 440194.50,
                      439197.36, 438789.82)
                      
north_carabanchel <- c(4472410.45, 4473019.57, 4471506.03, 4471105.25, 4470654.68, 4469661.77, 4469528.90, 4468757.01,
                       4468020.32, 4467864.38, 4468314.01, 4468617.08, 4470758.10, 4471288.38, 4471494.44, 4471840.89,
                       4472361.99, 4472410.45)

frame_coor_carabanchel<- data.frame(east_carabanchel,north_carabanchel)

utmcoor_carabanchel<-SpatialPoints(cbind(frame_coor_carabanchel$east_carabanchel, frame_coor_carabanchel$north_carabanchel), proj4string=CRS("+proj=utm +zone=30"))

longlatcoor_carabanchel<-spTransform(utmcoor_carabanchel,CRS("+proj=longlat"))

frame_coor_carabanchel$x <- coordinates(longlatcoor_carabanchel)[,1]
frame_coor_carabanchel$y <- coordinates(longlatcoor_carabanchel)[,2]

# el número de coordendas será igual al número de consumidores de Arganzuela

frame_coor_carabanchel<- frame_coor_carabanchel[,-c(1,2)]

n <- sum(consumption_prediction_2016$Distrito == "Carabanchel")

df <- frame_coor_carabanchel

coords <- as.matrix(df)


P1 = Polygon(coords)
Ps1 = SpatialPolygons(list(Polygons(list(P1), ID = "a")), proj4string=CRS("+proj=utm +zone=30"))
plot(Ps1, axes = TRUE)


coor_frame_random <- as.data.frame(spsample(Ps1,n,"random"))

# creamos dos columnas de lat y longitud en el data frame de predicciones para asignar los valores calculados


consumption_prediction_2016$lat[81493:83947] <- coor_frame_random$y

consumption_prediction_2016$lon[81493:83947] <- coor_frame_random$x

-----------------------------------
  
# Usera
  
  "https://www1.sedecatastro.gob.es/Cartografia/mapa.aspx?del=28&mun=92&refcat=28092A024000560000OK&final="

east_usera <- c(440210.88, 439873.83, 439493.26, 439101.93, 438828.06, 440319.16, 441025.16, 442086.15, 441456.41, 440210.88)

north_usera <- c(4471828.45, 4471420.65, 4471243.09, 4470757.73, 4468505.77, 4468341.83, 4468471.77, 4468126.77, 4470377.72, 4471828.45)

frame_coor_usera<- data.frame(east_usera,north_usera)

utmcoor_usera<-SpatialPoints(cbind(frame_coor_usera$east_usera, frame_coor_usera$north_usera), proj4string=CRS("+proj=utm +zone=30"))

longlatcoor_usera<-spTransform(utmcoor_usera,CRS("+proj=longlat"))

frame_coor_usera$x <- coordinates(longlatcoor_usera)[,1]
frame_coor_usera$y <- coordinates(longlatcoor_usera)[,2]

# el número de coordendas será igual al número de consumidores de Arganzuela

frame_coor_usera<- frame_coor_usera[,-c(1,2)]

n <- sum(consumption_prediction_2016$Distrito == "Usera")

df <- frame_coor_usera

coords <- as.matrix(df)


P1 = Polygon(coords)
Ps1 = SpatialPolygons(list(Polygons(list(P1), ID = "a")), proj4string=CRS("+proj=utm +zone=30"))
plot(Ps1, axes = TRUE)


coor_frame_random <- as.data.frame(spsample(Ps1,n,"random"))

# creamos dos columnas de lat y longitud en el data frame de predicciones para asignar los valores calculados


consumption_prediction_2016$lat[83948:86521] <- coor_frame_random$y

consumption_prediction_2016$lon[83948:86521] <- coor_frame_random$x


--------------------------------------
  
  # Puente vallecas
  
  "https://www1.sedecatastro.gob.es/Cartografia/mapa.aspx?del=28&mun=92&refcat=28092A024000560000OK&final="

east_puente_vallecas <- c(442859.62, 442276.29, 442689.92, 442307.39, 443043.86, 444377.81, 444568.45,
                          447945.94, 448223.96, 445370.06, 444446.48, 443611.42, 442859.62)


north_puente_vallecas <- c(4471705.19, 4470872.23, 4470528.31, 4470091.95, 4468287.82, 4469156.60, 4469853.20,
                           4470695.29, 4470968.41, 4471821.95, 4472863.05, 4473041.65, 4471705.19)

frame_coor_puente_vallecas<- data.frame(east_puente_vallecas,north_puente_vallecas)

utmcoor_puente_vallecas<-SpatialPoints(cbind(frame_coor_puente_vallecas$east_puente_vallecas, frame_coor_puente_vallecas$north_puente_vallecas), proj4string=CRS("+proj=utm +zone=30"))

longlatcoor_puente_vallecas<-spTransform(utmcoor_puente_vallecas,CRS("+proj=longlat"))

frame_coor_puente_vallecas$x <- coordinates(longlatcoor_puente_vallecas)[,1]
frame_coor_puente_vallecas$y <- coordinates(longlatcoor_puente_vallecas)[,2]

# el número de coordendas será igual al número de consumidores de Arganzuela

frame_coor_puente_vallecas<- frame_coor_puente_vallecas[,-c(1,2)]

n <- sum(consumption_prediction_2016$Distrito == "Puente_Vallecas")

df <- frame_coor_puente_vallecas

coords <- as.matrix(df)


P1 = Polygon(coords)
Ps1 = SpatialPolygons(list(Polygons(list(P1), ID = "a")), proj4string=CRS("+proj=utm +zone=30"))
plot(Ps1, axes = TRUE)


coor_frame_random <- as.data.frame(spsample(Ps1,n,"random"))

# creamos dos columnas de lat y longitud en el data frame de predicciones para asignar los valores calculados


consumption_prediction_2016$lat[86522:94421] <- coor_frame_random$y

consumption_prediction_2016$lon[86522:94421] <- coor_frame_random$x


--------------------------------------
  
  # Moratalaz
  
  "https://www1.sedecatastro.gob.es/Cartografia/mapa.aspx?del=28&mun=92&refcat=28092A024000560000OK&final="

east_moratalaz<- c(444135.64, 443558.32, 444492.40, 445350.26, 446258.89, 446618.75, 447047.83, 446791.01, 446305.98, 444906.91, 444135.64)

north_moratalaz <- c(4474277.05, 4473103.61, 4472944.79, 4471932.92, 4471647.23, 4471837.59, 4473078.16, 4473465.75, 4473621.04, 4473844.58, 4474277.05)

frame_coor_moratalaz<- data.frame(east_moratalaz,north_moratalaz)

utmcoor_moratalaz<-SpatialPoints(cbind(frame_coor_moratalaz$east_moratalaz, frame_coor_moratalaz$north_moratalaz), proj4string=CRS("+proj=utm +zone=30"))

longlatcoor_moratalaz<-spTransform(utmcoor_moratalaz,CRS("+proj=longlat"))

frame_coor_moratalaz$x <- coordinates(longlatcoor_moratalaz)[,1]
frame_coor_moratalaz$y <- coordinates(longlatcoor_moratalaz)[,2]

# el número de coordendas será igual al número de consumidores de Arganzuela

frame_coor_moratalaz<- frame_coor_moratalaz[,-c(1,2)]

n <- sum(consumption_prediction_2016$Distrito == "Moratalaz")

df <- frame_coor_moratalaz

coords <- as.matrix(df)


P1 = Polygon(coords)
Ps1 = SpatialPolygons(list(Polygons(list(P1), ID = "a")), proj4string=CRS("+proj=utm +zone=30"))
plot(Ps1, axes = TRUE)


coor_frame_random <- as.data.frame(spsample(Ps1,n,"random"))

# creamos dos columnas de lat y longitud en el data frame de predicciones para asignar los valores calculados


consumption_prediction_2016$lat[94422:95571] <- coor_frame_random$y

consumption_prediction_2016$lon[94422:95571] <- coor_frame_random$x

------------------------
  
  # Ciudad lineal
  
  "https://www1.sedecatastro.gob.es/Cartografia/mapa.aspx?del=28&mun=92&refcat=28092A024000560000OK&final="

east_ciudad_lineal <- c(444126.73, 444882.11, 445165.36, 446903.15, 446999.60, 447325.10, 445865.94, 446064.19,
                        445727.13, 445112.18, 444343.36, 443856.93, 443531.36, 444008.91, 443499.59, 442948.16,
                        442851.58, 442898.87, 443357.62, 443785.80, 443854.37, 444102.84, 444125.89, 444002.90, 
                        444126.73)


north_ciudad_lineal <- c(4474740.79, 4474394.63, 4475385.49, 4474174.88, 4473833.60, 4473839.52, 4476578.31, 4476658.92,
                         4477313.56, 4477683.08, 4478947.82, 4479410.74, 4480999.96, 4481566.21, 4481697.12, 4481701.31,
                         4480910.82, 4480635.77, 4479795.85, 4478710.04, 4477971.31, 4477058.89, 4476837.21, 4475808.46,
                         4474740.79)

frame_coor_ciudad_lineal<- data.frame(east_ciudad_lineal,north_ciudad_lineal)

utmcoor_ciudad_lineal<-SpatialPoints(cbind(frame_coor_ciudad_lineal$east_ciudad_lineal, frame_coor_ciudad_lineal$north_ciudad_lineal), proj4string=CRS("+proj=utm +zone=30"))

longlatcoor_ciudad_lineal<-spTransform(utmcoor_ciudad_lineal,CRS("+proj=longlat"))

frame_coor_ciudad_lineal$x <- coordinates(longlatcoor_ciudad_lineal)[,1]
frame_coor_ciudad_lineal$y <- coordinates(longlatcoor_ciudad_lineal)[,2]

# el número de coordendas será igual al número de consumidores de Arganzuela

frame_coor_ciudad_lineal<- frame_coor_ciudad_lineal[,-c(1,2)]

n <- sum(consumption_prediction_2016$Distrito == "Ciudad_Lineal")

df <- frame_coor_ciudad_lineal

coords <- as.matrix(df)


P1 = Polygon(coords)
Ps1 = SpatialPolygons(list(Polygons(list(P1), ID = "a")), proj4string=CRS("+proj=utm +zone=30"))
plot(Ps1, axes = TRUE)


coor_frame_random <- as.data.frame(spsample(Ps1,n,"random"))

# creamos dos columnas de lat y longitud en el data frame de predicciones para asignar los valores calculados


consumption_prediction_2016$lat[95572:113461] <- coor_frame_random$y

consumption_prediction_2016$lon[95572:113461] <- coor_frame_random$x

---------------

  
  #HOrtaleza
  
  "https://www1.sedecatastro.gob.es/Cartografia/mapa.aspx?del=28&mun=92&refcat=28092A024000560000OK&final="

east_hortaleza<- c(444021.56, 443034.73, 443065.14, 444289.94, 444282.15, 444437.03, 444772.39, 445072.70, 445358.13, 446431.80,
                   447288.71, 447630.92, 448377.09, 448886.95, 448938.50, 448743.74, 448075.66, 447723.60, 446916.41, 447155.15, 
                   446721.81, 447230.47, 447873.20, 448726.74, 448782.33, 445129.70, 444409.38, 443906.51, 443575.98, 444021.56)

north_hortaleza <- c(4481607.11, 4481721.14, 4482471.06, 4483933.21, 4484543.87, 4484903.31, 4484638.57, 4484640.46, 4484294.15, 4484286.37,
                     4484460.59, 4483982.82, 4483608.79, 4483564.31, 4482678.67, 4482479.16, 4482266.53, 4481350.75, 4480692.29, 4480112.49,
                     4479951.56, 4479119.65, 4478602.54, 4478194.74, 4477894.97, 4477826.51, 4478967.84, 4479434.97, 4480913.53, 4481607.11)

frame_coor_hortaleza<- data.frame(east_hortaleza,north_hortaleza)

utmcoor_hortaleza<-SpatialPoints(cbind(frame_coor_hortaleza$east_hortaleza, frame_coor_hortaleza$north_hortaleza), proj4string=CRS("+proj=utm +zone=30"))

longlatcoor_hortaleza<-spTransform(utmcoor_hortaleza,CRS("+proj=longlat"))

frame_coor_hortaleza$x <- coordinates(longlatcoor_hortaleza)[,1]
frame_coor_hortaleza$y <- coordinates(longlatcoor_hortaleza)[,2]

# el número de coordendas será igual al número de consumidores de Arganzuela

frame_coor_hortaleza<- frame_coor_hortaleza[,-c(1,2)]

n <- sum(consumption_prediction_2016$Distrito == "Hortaleza")

df <- frame_coor_hortaleza

coords <- as.matrix(df)


P1 = Polygon(coords)
Ps1 = SpatialPolygons(list(Polygons(list(P1), ID = "a")), proj4string=CRS("+proj=utm +zone=30"))
plot(Ps1, axes = TRUE)


coor_frame_random <- as.data.frame(spsample(Ps1,n,"random"))

# creamos dos columnas de lat y longitud en el data frame de predicciones para asignar los valores calculados


consumption_prediction_2016$lat[113462:139587] <- coor_frame_random$y

consumption_prediction_2016$lon[113462:139587] <- coor_frame_random$x


---------------------------
  
  
  #Villaverde
  
  "https://www1.sedecatastro.gob.es/Cartografia/mapa.aspx?del=28&mun=92&refcat=28092A024000560000OK&final="

east_villaverde<- c(438876.72, 438507.61, 439412.85, 441288.78, 442048.60, 442438.40, 442865.91, 443686.99, 443534.51,
                    442868.50, 442556.36, 442352.03, 442354.83, 442089.89, 441103.36, 440306.59, 438876.72)


north_villaverde <- c(4468406.82, 4465115.57, 4464335.80, 4464218.20, 4464861.48, 4465133.76, 4465487.91, 4465535.13, 4466099.06,
                      4466371.10, 4467075.87, 4467315.65, 4467681.16, 4468077.46, 4468454.73, 4468317.29, 4468406.82)


frame_coor_villaverde<- data.frame(east_villaverde,north_villaverde)

utmcoor_villaverde<-SpatialPoints(cbind(frame_coor_villaverde$east_villaverde, frame_coor_villaverde$north_villaverde), proj4string=CRS("+proj=utm +zone=30"))

longlatcoor_villaverde<-spTransform(utmcoor_villaverde,CRS("+proj=longlat"))

frame_coor_villaverde$x <- coordinates(longlatcoor_villaverde)[,1]
frame_coor_villaverde$y <- coordinates(longlatcoor_villaverde)[,2]

# el número de coordendas será igual al número de consumidores de Arganzuela

frame_coor_villaverde<- frame_coor_villaverde[,-c(1,2)]

n <- sum(consumption_prediction_2016$Distrito == "Villaverde")

df <- frame_coor_villaverde

coords <- as.matrix(df)


P1 = Polygon(coords)
Ps1 = SpatialPolygons(list(Polygons(list(P1), ID = "a")), proj4string=CRS("+proj=utm +zone=30"))
plot(Ps1, axes = TRUE)


coor_frame_random <- as.data.frame(spsample(Ps1,n,"random"))

# creamos dos columnas de lat y longitud en el data frame de predicciones para asignar los valores calculados


consumption_prediction_2016$lat[139588:161755] <- coor_frame_random$y

consumption_prediction_2016$lon[139588:161755] <- coor_frame_random$x 

--------------------------
  
  #Vallecas
  
  "https://www1.sedecatastro.gob.es/Cartografia/mapa.aspx?del=28&mun=92&refcat=28092A024000560000OK&final="

east_vallecas<- c(442666.36, 442787.07, 443213.71, 444920.91, 445605.43, 445904.75, 446756.83, 447861.05,
                  448156.28, 449904.61, 451075.77, 448927.17, 449157.79, 448820.83, 447245.50, 446978.93,
                  444740.32, 444483.95, 443484.75, 442666.36)


north_vallecas <- c(4467982.69, 4467591.61, 4467304.98, 4467891.90, 4467907.44, 4468250.25, 4468646.60, 4467965.37, 4468328.82,
                    4467142.39, 4468432.43, 4469534.88, 4470112.22, 4470865.80, 4471307.74, 4470324.36, 4469683.60, 4469016.20,
                    4468255.75, 4467982.69)

frame_coor_vallecas<- data.frame(east_vallecas,north_vallecas)

utmcoor_vallecas<-SpatialPoints(cbind(frame_coor_vallecas$east_vallecas, frame_coor_vallecas$north_vallecas), proj4string=CRS("+proj=utm +zone=30"))

longlatcoor_vallecas<-spTransform(utmcoor_vallecas,CRS("+proj=longlat"))

frame_coor_vallecas$x <- coordinates(longlatcoor_vallecas)[,1]
frame_coor_vallecas$y <- coordinates(longlatcoor_vallecas)[,2]

# el número de coordendas será igual al número de consumidores de Arganzuela

frame_coor_vallecas<- frame_coor_vallecas[,-c(1,2)]

n <- sum(consumption_prediction_2016$Distrito == "Vallecas")

df <- frame_coor_vallecas

coords <- as.matrix(df)


P1 = Polygon(coords)
Ps1 = SpatialPolygons(list(Polygons(list(P1), ID = "a")), proj4string=CRS("+proj=utm +zone=30"))
plot(Ps1, axes = TRUE)


coor_frame_random <- as.data.frame(spsample(Ps1,n,"random"))

# creamos dos columnas de lat y longitud en el data frame de predicciones para asignar los valores calculados


consumption_prediction_2016$lat[161756:168490] <- coor_frame_random$y

consumption_prediction_2016$lon[161756:168490] <- coor_frame_random$x

-----------------------
  
  #Vicalvaro
  
  "https://www1.sedecatastro.gob.es/Cartografia/mapa.aspx?del=28&mun=92&refcat=28092A024000560000OK&final="

east_vicalvaro<- c(446596.02, 447569.03, 448172.38, 448222.62, 450051.70, 450813.59, 451011.84, 451484.24, 453016.84,
                   453761.56, 453935.50, 453028.89, 451410.91, 449654.64, 448747.01, 446596.02)


north_vicalvaro <- c(4471538.10, 4473965.02, 4474239.85, 4473759.40, 4473135.53, 4474345.16, 4473794.00, 4473585.75, 4473596.51,
                     4473444.15, 4471579.76, 4471573.07, 4472441.22, 4469833.79, 4470919.67, 4471538.10)
frame_coor_vicalvaro<- data.frame(east_vicalvaro,north_vicalvaro)

utmcoor_vicalvaro<-SpatialPoints(cbind(frame_coor_vicalvaro$east_vicalvaro, frame_coor_vicalvaro$north_vicalvaro), proj4string=CRS("+proj=utm +zone=30"))

longlatcoor_vicalvaro<-spTransform(utmcoor_vicalvaro,CRS("+proj=longlat"))

frame_coor_vicalvaro$x <- coordinates(longlatcoor_vicalvaro)[,1]
frame_coor_vicalvaro$y <- coordinates(longlatcoor_vicalvaro)[,2]

# el número de coordendas será igual al número de consumidores de Arganzuela

frame_coor_vicalvaro<- frame_coor_vicalvaro[,-c(1,2)]

n <- sum(consumption_prediction_2016$Distrito == "Vicalvaro")

df <- frame_coor_vicalvaro

coords <- as.matrix(df)


P1 = Polygon(coords)
Ps1 = SpatialPolygons(list(Polygons(list(P1), ID = "a")), proj4string=CRS("+proj=utm +zone=30"))
plot(Ps1, axes = TRUE)


coor_frame_random <- as.data.frame(spsample(Ps1,n,"random"))

# creamos dos columnas de lat y longitud en el data frame de predicciones para asignar los valores calculados


consumption_prediction_2016$lat[168491:169489] <- coor_frame_random$y

consumption_prediction_2016$lon[168491:169489] <- coor_frame_random$x

--------------------------------
  
  
  #San blas
  
  "https://www1.sedecatastro.gob.es/Cartografia/mapa.aspx?del=28&mun=92&refcat=28092A024000560000OK&final="

east_san_blas<- c(448164.86, 447293.15, 445935.82, 446187.58, 445707.17, 445092.55, 445397.47, 445993.49, 446648.90,
                  452758.69, 454531.53, 454579.90, 452702.94, 449764.43, 449061.47, 448164.86)


north_san_blas <- c(4474342.49, 4473983.36, 4476561.40, 4476637.52, 4477399.84, 4477814.48, 4477845.06, 4477705.39, 4477807.33,
                    4477737.58, 4477447.71, 4477275.15, 4476733.02, 4476990.06, 4474742.56, 4474342.49)

frame_coor_san_blas<- data.frame(east_san_blas,north_san_blas)

utmcoor_san_blas<-SpatialPoints(cbind(frame_coor_san_blas$east_san_blas, frame_coor_san_blas$north_san_blas), proj4string=CRS("+proj=utm +zone=30"))

longlatcoor_san_blas<-spTransform(utmcoor_san_blas,CRS("+proj=longlat"))

frame_coor_san_blas$x <- coordinates(longlatcoor_san_blas)[,1]
frame_coor_san_blas$y <- coordinates(longlatcoor_san_blas)[,2]

# el número de coordendas será igual al número de consumidores de Arganzuela

frame_coor_san_blas<- frame_coor_san_blas[,-c(1,2)]

n <- sum(consumption_prediction_2016$Distrito == "San_Blas")

df <- frame_coor_san_blas

coords <- as.matrix(df)


P1 = Polygon(coords)
Ps1 = SpatialPolygons(list(Polygons(list(P1), ID = "a")), proj4string=CRS("+proj=utm +zone=30"))
plot(Ps1, axes = TRUE)


coor_frame_random <- as.data.frame(spsample(Ps1,n,"random"))
# creamos dos columnas de lat y longitud en el data frame de predicciones para asignar los valores calculados


consumption_prediction_2016$lat[169490:172189] <- coor_frame_random$y

consumption_prediction_2016$lon[169490:172189] <- coor_frame_random$x


------------------
  
  
  #Barajas
  
  "https://www1.sedecatastro.gob.es/Cartografia/mapa.aspx?del=28&mun=92&refcat=28092A024000560000OK&final="

east_barajas<- c(448852.35, 448785.05, 447439.26, 446841.17, 447204.37, 447089.59, 447930.11, 448037.35, 449210.43,
                 449076.23, 449689.03, 451531.85, 453032.49, 452903.23, 453245.67, 454036.93, 454119.53, 452370.42,
                 452092.36, 455001.53, 455245.56, 454841.83, 454597.05, 454503.38, 452611.09, 448852.35)

north_barajas <- c(4477898.59, 4478292.77, 4478954.15, 4479950.71, 4480087.54, 4480736.16, 4481455.90, 4482082.34, 4482730.11,
                   4483567.11, 4483534.28, 4484747.38, 4484618.97, 4483689.56, 4483187.41, 4482727.57, 4482108.14, 4482069.88,
                   4479132.06, 4478917.18, 4478419.51, 4478376.82, 4478066.62, 4477558.62, 4477836.95, 4477898.59)


frame_coor_barajas<- data.frame(east_barajas,north_barajas)

utmcoor_barajas<-SpatialPoints(cbind(frame_coor_barajas$east_barajas, frame_coor_barajas$north_barajas), proj4string=CRS("+proj=utm +zone=30"))

longlatcoor_barajas<-spTransform(utmcoor_barajas,CRS("+proj=longlat"))

frame_coor_barajas$x <- coordinates(longlatcoor_barajas)[,1]
frame_coor_barajas$y <- coordinates(longlatcoor_barajas)[,2]

# el número de coordendas será igual al número de consumidores de Arganzuela

frame_coor_barajas<- frame_coor_barajas[,-c(1,2)]

n <- sum(consumption_prediction_2016$Distrito == "Barajas")

df <- frame_coor_barajas
coords <- as.matrix(df)


P1 = Polygon(coords)
Ps1 = SpatialPolygons(list(Polygons(list(P1), ID = "a")), proj4string=CRS("+proj=utm +zone=30"))
plot(Ps1, axes = TRUE)


coor_frame_random <- as.data.frame(spsample(Ps1,n,"random"))

# creamos dos columnas de lat y longitud en el data frame de predicciones para asignar los valores calculados


consumption_prediction_2016$lat[172190:178598] <- coor_frame_random$y

consumption_prediction_2016$lon[172190:178598] <- coor_frame_random$x

---------------------------------------
  
# guardamos el dataset de predicciones con las coordendas calculadas

  
write.csv(consumption_prediction_2016, file="consumption_pred_madrid_2016_by_coor.csv")
  
  
# cargamos ahora el paquete de ggmap para visualizar que tal queda, teneindo en cuenta al distribución

p<- ggplot(consumption_pred_madrid_2016_by_coor, aes(consumption_pred_madrid_2016_by_coor$Tipo_consumidor,consumption_pred_madrid_2016_by_coor$`2016/01`)) 

p2 <- ggplot(consumption_pred_madrid_2016_by_coor, aes(consumption_pred_madrid_2016_by_coor$Distrito,consumption_pred_madrid_2016_by_coor$`2016/01`)) 

# podemos ver al distribución por distritos

p + geom_boxplot(outlier.colour=NA, ylab = " Consumo en m3", xlab = "tipo de consumidor") +  coord_cartesian(ylim = c(0, 100))

p2 + geom_boxplot(outlier.colour=NA,  ylab = " Consumo en m3",  xlab = "tipo de consumidor") +  coord_cartesian(ylim = c(0, 40))
  
install.packages("ggmap")

library("ggmap")

install.packages("rgdal")

#cargamos el paquete rgdal, especialmente indicado para tratar los mapas tipo shape de http://centrodedescargas.cnig.es:

"http://centrodedescargas.cnig.es/CentroDescargas"

library("rgdal")

require(rgdal)


list.files()

map_madrid <- readOGR(dsn = ".", layer = "MANZANA")

map_madrid_vias <- readOGR(dsn = ".", layer = "PORTAL_PK")

map_call_madrid <- readOGR(dsn = ".", layer = "call2016")


class(map_madrid_vias)

class(map_call_madrid)


# convertimos el shape en un data frame

map_madrid_df <- fortify(map_madrid)

map_madrod_vias_df <- fortify(map_madrid_vias)

map_call_madrid_df <- fortify(map_call_madrid)

utmcoor_call<-SpatialPoints(cbind(map_call_madrid_df$long, map_call_madrid_df$lat), proj4string=CRS("+proj=utm +zone=30"))

longlatcoor_call<-spTransform(utmcoor_call,CRS("+proj=longlat"))

map_call_madrid_df$x <- coordinates(longlatcoor_call)[,1]
map_call_madrid_df$y <- coordinates(longlatcoor_call)[,2]

map_call_madrid_df$long <- map_call_madrid_df$x

map_call_madrid_df$lat <- map_call_madrid_df$y


# Ahora el shapefile se puede trazar como geom_path o geom_polygon.
# Los path manejan el recorte mejor. Los polígonos se pueden rellenar.
# Necesitamos la aes long, lat, y group.



map_dist_madrid <- ggplot() +  geom_path(data = map_madrid_df, aes(x = long, y = lat, group = group), color = 'grey', size = 0.1)

map_call_dist_madrid <- ggplot() +  geom_path(data = map_call_madrid_df, aes(x = long, y = lat, group = group), color = 'grey', size = 0.1)

print(map_dist_madrid)

class(water_dist_map)



water_dist_map <- map_call_dist_madrid + geom_point(data=consumption_pred_madrid_2016_by_coor, aes(x=consumption_pred_madrid_2016_by_coor$lon, 
                                  y=consumption_pred_data_madrid_2016_by_coor$lat, colour=consumption_pred_data_madrid_2016_by_coor$`2016/08`),
                                                 alpha = 0.3, show.legend = FALSE, size=0.1, color= "blue")
library("sp")

require(sp)
require(maptools)
library("maptools")

water_dist_map_sp <- shapefile(water_dist_map)

print(water_dist_map)

#es una primera aproximación a la versión gráfica, exploremos un poco más con leaflet para poder cagar uan distribución dinámica y exportable

install.packages("leaflet")

install.packages("sp")

library ("leaflet")

#creemso un shape con los puntos de consumo

sp_consumtion_madrid<-SpatialPoints(cbind(consumption_pred_data_madrid_2016_by_coor$lat, consumption_pred_data_madrid_2016_by_coor$lon), proj4string=CRS("+proj=utm +zone=30"))


leaflet(data = map_call_madrid) %>% addTiles() %>% addProviderTiles(providers$OpenStreetMap) %>% 
  addPolygons(fill = FALSE, stroke = TRUE, color = "#03F") %>% addLegend("bottomright", colors = "#03F", labels = "Consumption Water Point") %>% 
  setView(-3.7, 40.41, zoom = 12)
                                                                         
# creamos un leaflet con los datos de matriz de predicción de consumos

consumption_pred_madrid_2016_by_coor$Anual_consumption <- rowSums(consumption_pred_madrid_2016_by_coor[, c(3:14)])

write.csv(consumption_pred_madrid_2016_by_coor, file="consumption_pred_madrid_2016_by_coor.csv")


# utilizamos un data frame auxiliar marker solo con los datos que nos interesa exportar, totalizado de consumo por tipo y coordenadas

mark_data <- data.frame(long= consumption_pred_madrid_2016_by_coor$lon, lat= consumption_pred_madrid_2016_by_coor$lat, val=consumption_pred_madrid_2016_by_coor$Anual_consumption)

str(mark_data)

#finalmente podemos ver los consumidores

install.packages("pals")

library(pals)

cluster_consumidores_madrid <- leaflet(data = mark_data) %>% addTiles() %>% addMarkers(clusterOptions = markerClusterOptions(~long, ~lat, popup = ~as.character(val)), label = ~as.character(paste(val,"m³",sep=" "), color="blue"))

cluster_consumidores_madrid
saveWidget(cluster_consumidores_madrid, file="Cluster consumidores Madrid.html")

# podemos mejorar estas leyendas añadiendo gradientes de colores

consumption_pred_madrid_2016_by_coor$Tipo_consumidor <- as.factor(consumption_pred_madrid_2016_by_coor$Tipo_consumidor)

class(consumption_pred_madrid_2016_by_coor$Tipo_consumidor)

#Creamos uan paleta de colores

factpal <- topo.colors(7,alpha = 1)

factpal

pal <- colorFactor(factpal, domain = consumption_pred_madrid_2016_by_coor$Tipo_consumidor, levels = FALSE)


cluster_consumidores_madrid_p2 <- leaflet(data = consumption_pred_madrid_2016_by_coor) %>% addTiles() %>% addCircleMarkers(lng = ~lon,lat =  ~lat, color= ~pal(consumption_pred_madrid_2016_by_coor$Tipo_consumidor), label= paste("Consumo: ", consumption_pred_madrid_2016_by_coor$Anual_consumption, "[m3] ", "_Tipo de consumidor: ", consumption_pred_madrid_2016_by_coor$Tipo_consumidor), clusterOptions = markerClusterOptions()) %>% 
                                  addLegend("bottomright", colors = factpal, labels = unique(consumption_pred_madrid_2016_by_coor$Tipo_consumidor), title = "Tipo de consumidor" )

cluster_consumidores_madrid_p2

install.packages("htmlwidgets")

library(htmlwidgets)

saveWidget(cluster_consumidores_madrid_p2, file="Cluster consumidores Madrid.html", selfcontained = TRUE)



